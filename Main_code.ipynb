{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tqdm import trange\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import spacy \n",
    "  \n",
    "# Load English tokenizer, tagger,  \n",
    "# parser, NER and word vectors \n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "#Feature importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "#importing machine learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "#Secondary imports\n",
    "import pandas_profiling as pp\n",
    "from scipy.stats import pearsonr\n",
    "import pickle\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "result = pd.read_csv('results.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = re.compile('([\\s.,;:()]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meals can be served</td>\n",
       "      <td>in rooms at 9:00 p. m.</td>\n",
       "      <td>'outside the room at 3:00 p. m.', 'in the dini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It can be inferred from the passage that</td>\n",
       "      <td>The local government can deal with the problem...</td>\n",
       "      <td>'If some tragedies occur again ', ' relevant d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The author called Tommy 's parents in order to</td>\n",
       "      <td>help them realize their influence on Tommy</td>\n",
       "      <td>'blame Tommy for his failing grades', 'blame T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It can be inferred from the passage that</td>\n",
       "      <td>the writer is not very willing to use idioms</td>\n",
       "      <td>'idioms are the most important part in a langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can we deal with snake wounds according to...</td>\n",
       "      <td>Stay calm and do n't move .</td>\n",
       "      <td>'Cut the wound and suck the poison out .'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                                Meals can be served   \n",
       "1           It can be inferred from the passage that   \n",
       "2     The author called Tommy 's parents in order to   \n",
       "3           It can be inferred from the passage that   \n",
       "4  How can we deal with snake wounds according to...   \n",
       "\n",
       "                                         answer_text  \\\n",
       "0                             in rooms at 9:00 p. m.   \n",
       "1  The local government can deal with the problem...   \n",
       "2         help them realize their influence on Tommy   \n",
       "3       the writer is not very willing to use idioms   \n",
       "4                        Stay calm and do n't move .   \n",
       "\n",
       "                                          distractor  \n",
       "0  'outside the room at 3:00 p. m.', 'in the dini...  \n",
       "1  'If some tragedies occur again ', ' relevant d...  \n",
       "2  'blame Tommy for his failing grades', 'blame T...  \n",
       "3  'idioms are the most important part in a langu...  \n",
       "4          'Cut the wound and suck the poison out .'  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What 'S the main idea of the text ?</td>\n",
       "      <td>The lack of career -- based courses in US high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the summer high season , Finland does nt se...</td>\n",
       "      <td>the sun is out at night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you want to apply for Chinese Business Inte...</td>\n",
       "      <td>have to get confirmed at least twice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That afternoon , the boy 's clothes were dry b...</td>\n",
       "      <td>nobody made room for him in the water .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which of the following statements is NOT true ?</td>\n",
       "      <td>There are twelve countries in the World Wildli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                What 'S the main idea of the text ?   \n",
       "1  In the summer high season , Finland does nt se...   \n",
       "2  If you want to apply for Chinese Business Inte...   \n",
       "3  That afternoon , the boy 's clothes were dry b...   \n",
       "4    Which of the following statements is NOT true ?   \n",
       "\n",
       "                                         answer_text  \n",
       "0  The lack of career -- based courses in US high...  \n",
       "1                            the sun is out at night  \n",
       "2               have to get confirmed at least twice  \n",
       "3            nobody made room for him in the water .  \n",
       "4  There are twelve countries in the World Wildli...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will be first approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['answer_text_broken'] = train['answer_text'].str.lower()\n",
    "train['answer_text_broken'] = train['answer_text_broken'].apply(lambda x : re.split(tokenizer, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The local government can deal with the problem of lacking money by some means .'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(train['answer_text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syn_ant(word):\n",
    "    ant = list()\n",
    "    syn = list()\n",
    "\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            syn.append(lemma.name())    #add the synonyms\n",
    "            if lemma.antonyms():    #When antonyms are available, add them into the list\n",
    "                ant.append(lemma.antonyms()[0].name())\n",
    "    ant = list(set(ant))\n",
    "    syn = list(set(syn))\n",
    "    \n",
    "    return syn[:4], ant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commencing 3 stage prediction TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['answer_text_broken'] = test['answer_text'].str.lower()\n",
    "test['answer_text_broken'] = test['answer_text_broken'].apply(lambda x : re.split(tokenizer, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "centre = test['answer_text_broken'].values\n",
    "done = [0 for _ in range(len(centre))]\n",
    "dist = [[] for _ in range(len(centre))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13500/13500 [00:00<00:00, 48671.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#Going to execute 3 stage approach for all the 2 distractors\n",
    "for i in trange(len(centre)):\n",
    "    \n",
    "    #Stage 1 Changing numbers in the options!\n",
    "    for j in range(len(centre[i])):\n",
    "        try:\n",
    "            int(centre[i][j])\n",
    "            centre[i][j] = str(int(centre[i][j]) + 1)\n",
    "            dist[i].append(''.join(centre[i]))\n",
    "            centre[i][j] = str(int(centre[i][j]) + 1)\n",
    "            dist[i].append(''.join(centre[i]))\n",
    "            dist[i].append('No of the above')\n",
    "            done[i] += 3\n",
    "            break\n",
    "        except:\n",
    "#             pass\n",
    "            if done[i] == 0:\n",
    "                dist[i].append('~'+test['answer_text'].values[i])\n",
    "                dist[i].append('~' + test['answer_text'].values[i])\n",
    "                dist[i].append('No of the above')\n",
    "                done[i]+=3\n",
    "                break\n",
    "\n",
    "        \n",
    "    #Stage 2 Changing all the proposition in the sentence by antonyms  \n",
    "    if done[i] == 0:\n",
    "        st2 = nlp(test['answer_text'].values[i])\n",
    "        for j in range(len(st2)):\n",
    "            if st2[j].pos_ == 'PROPN':\n",
    "                if len(syn_ant(str(st2[j]))[1])>2:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[1][0], syn_ant(str(st2[j]))[1][1] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "                elif len(syn_ant(str(st2[j]))[1]) == 1:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[1][0], syn_ant(str(st2[j]))[0][0] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "                elif len(syn_ant(str(st2[j]))[0]) >= 2:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[0][0], syn_ant(str(st2[j]))[0][1] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "    #Stage 3 Changing all the adjectives        \n",
    "    if done[i] == 0:\n",
    "        st2 = nlp(train['answer_text'].values[i])\n",
    "        for j in range(len(st2)):\n",
    "            if st2[j].pos_ == 'ADJ':\n",
    "                if len(syn_ant(str(st2[j]))[1])>2:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[1][0], syn_ant(str(st2[j]))[1][1] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "                elif len(syn_ant(str(st2[j]))[1]) == 1:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[1][0], syn_ant(str(st2[j]))[0][0] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "                elif len(syn_ant(str(st2[j]))[0]) >= 2:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[0][0], syn_ant(str(st2[j]))[0][1] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "    #Stage 4 Changing the conjunctions!               \n",
    "    if done[i] == 0:\n",
    "        st2 = nlp(test['answer_text'].values[i])\n",
    "        for j in range(len(st2)):\n",
    "            if st2[j].pos_ == 'CCONJ' or st2[j].pos_ == 'CONJ':\n",
    "                c1, c2 = str(st2), str(st2)\n",
    "                chan = False\n",
    "                if c1 == 'AND':\n",
    "                    c1 = 'OR'\n",
    "                    c2 = 'NOR'\n",
    "                    chan = True\n",
    "                elif c1 == 'OR':\n",
    "                    c1 = 'AND'\n",
    "                    c2 = 'NOR'\n",
    "                    chan = True\n",
    "                if c2 == 'AND':\n",
    "                    c2 = 'OR'\n",
    "                    c1 = 'NOR'\n",
    "                    chan = True\n",
    "                elif c2 == 'OR':\n",
    "                    c2 = 'AND'\n",
    "                    c1 = 'NOR'\n",
    "                    chan = True\n",
    "                if chan==False:\n",
    "                    c1 ,c2= 'AND', 'OR'\n",
    "                c1 = c1.replace(str(st2[j]), an1)\n",
    "                c2 = c2.replace(str(st2[j]), an2)\n",
    "                dist[i].append(c1)\n",
    "                dist[i].append(c2)\n",
    "                dist[i].append('None of the above')\n",
    "                done[i]+=3\n",
    "                break\n",
    "                \n",
    "    #Stage 5 Changing the adpositions!               \n",
    "    if done[i] == 0:\n",
    "        st2 = nlp(test['answer_text'].values[i])\n",
    "        for j in range(len(st2)):\n",
    "            if st2[j].pos_ == 'ADP':\n",
    "                if len(syn_ant(str(st2[j]))[1])>2:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[1][0], syn_ant(str(st2[j]))[1][1] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "                elif len(syn_ant(str(st2[j]))[1]) == 1:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[1][0], syn_ant(str(st2[j]))[0][0] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "                elif len(syn_ant(str(st2[j]))[0]) >= 2:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[0][0], syn_ant(str(st2[j]))[0][1] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "    # Stage 6 Changing Nouns                \n",
    "    if done[i] == 0:\n",
    "        st2 = nlp(test['answer_text'].values[i])\n",
    "        for j in range(len(st2)):\n",
    "            if st2[j].pos_ == 'NOUN':\n",
    "                if len(syn_ant(str(st2[j]))[1])>2:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[1][0], syn_ant(str(st2[j]))[1][1] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "                elif len(syn_ant(str(st2[j]))[1]) == 1:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[1][0], syn_ant(str(st2[j]))[0][0] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "                elif len(syn_ant(str(st2[j]))[0]) >= 2:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[0][0], syn_ant(str(st2[j]))[0][1] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "    \n",
    "    # Stage 7, Changing Adverbs\n",
    "    if done[i] == 0:\n",
    "        st2 = nlp(test['answer_text'].values[i])\n",
    "        for j in range(len(st2)):\n",
    "            if st2[j].pos_ == 'ADV':\n",
    "                if len(syn_ant(str(st2[j]))[1])>2:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[1][0], syn_ant(str(st2[j]))[1][1] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "                elif len(syn_ant(str(st2[j]))[1]) == 1:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[1][0], syn_ant(str(st2[j]))[0][0] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break\n",
    "                    \n",
    "                elif len(syn_ant(str(st2[j]))[0]) >= 2:\n",
    "                    c1, c2 = str(st2), str(st2)\n",
    "                    an1, an2 = syn_ant(str(st2[j]))[0][0], syn_ant(str(st2[j]))[0][1] \n",
    "                    c1 = c1.replace(str(st2[j]), an1)\n",
    "                    c2 = c2.replace(str(st2[j]), an2)\n",
    "                    dist[i].append(c1)\n",
    "                    dist[i].append(c2)\n",
    "                    dist[i].append('None of the above')\n",
    "                    done[i]+=3\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(done, return_counts=True)\n",
    "\n",
    "test.drop(['answer_text_broken'], axis=1, inplace=True)\n",
    "\n",
    "test['distractor'] = dist\n",
    "\n",
    "test['distractors'] = test['distractor'].apply(lambda x: \"’,’\".join(x))\n",
    "\n",
    "test['distractors'] = test['distractors'].apply(lambda x: \"'\" + x + \"'\")\n",
    "\n",
    "test.drop(['distractor'], axis=1, inplace=True)\n",
    "\n",
    "test.columns = ['question', 'answer_text', 'distractor']\n",
    "\n",
    "test.to_csv('submission_shivam13juna@gmail.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
